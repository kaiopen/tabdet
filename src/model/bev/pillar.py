from typing import Any, Dict, Sequence, Tuple

import torch
from torch import nn

from kaitorch.typing import TorchTensor, TorchBool, TorchFloat, TorchInt64
from kaitorch.nn.conv import Conv1dBlock
from kaitorch.nn.mlp import Linear1dBlock


class Pillar(nn.Module):
    def __init__(
        self,
        in_channels: int,
        channels: Sequence[int],  # 64, 64
        size: Sequence[int],
        activation: str = 'relu',
        activation_kw: Dict[str, Any] = {'inplace': True},
        *args, **kwargs
    ) -> None:
        r'''Encode pillars into a map.

        ### Args:
            - in_channels: number of channels of the input pillars.
            - channels: numbers of out channels for MLPs.
            - size: size of the map to be generated. The form of it should be
                `(H, W)`.
            - activation: `relu`, `leakyrelu` or other activation.
            - activation_kw: arguments of activation.

        ### Methods:
            - forward

        forward
        ### Args:
            Generated by a neighbor extractor.
            - Neighbors. Its shape should be `(X, in_channels)`.
            - Indices for picked neighbors. Its shape should be
                `(L < H * W, num_neighbor)`
            - Mask indexing nonempty pillars. Its shape should be `(B, H * W)`.
                And it should meet `sum(mask) == L`.

        ### Returns:
            - Feature map. Its shape is `(B, channels[-1], H, W)`.

        '''
        super().__init__()
        self._h, self._w = size

        if 0 == (n := len(channels)):
            raise ValueError(
                'The `channels` should be a sequence containing one item at least.'
            )
        elif 1 == n:
            out_channels = channels[0]
            self._mlp = Linear1dBlock(
                in_channels, out_channels,
                activation=activation,
                activation_kw=activation_kw
            )
            self.register_buffer(
                '_zeros', torch.zeros((1, out_channels)), persistent=False
            )
            self._fn = self._once
        else:
            out_channels = channels[0] // 2
            self._mlp = Linear1dBlock(
                in_channels, out_channels,
                activation=activation,
                activation_kw=activation_kw
            )
            self.register_buffer(
                '_zeros', torch.zeros((1, out_channels)), persistent=False
            )

            self._mlps = nn.ModuleList()
            for c in channels[1: -1]:
                in_channels = out_channels * 2
                out_channels = c // 2
                self._mlps.append(
                    Conv1dBlock(
                        in_channels, out_channels, 1,
                        activation=activation,
                        activation_kw=activation_kw
                    )
                )
            self._mlps.append(
                Conv1dBlock(
                    out_channels * 2, channels[-1], 1,
                    activation=activation,
                    activation_kw=activation_kw
                )
            )
            self._fn = self._multi

        self._out_channels = channels[-1]

    def _once(self, x: TorchTensor[TorchFloat]) -> TorchTensor[TorchFloat]:
        return torch.max(x, dim=1)[0]

    def _multi(self, x: TorchTensor[TorchFloat]) -> TorchTensor[TorchFloat]:
        x = x.permute(0, 2, 1).contiguous()  # (L, C, k)
        for mlp in self._mlps:
            x = mlp(
                torch.cat(
                    (x, torch.max(x, dim=2, keepdim=True)[0].expand_as(x)),
                    dim=1
                )
            )
        return torch.max(x, dim=2)[0]  # (L, C)

    def forward(
        self,
        x: Tuple[
            TorchTensor[TorchFloat],
            TorchTensor[TorchInt64],
            TorchTensor[TorchBool]
        ]
    ) -> TorchTensor[TorchFloat]:
        neighbors, indices, mask = x
        batch_size, num_pillar = mask.shape
        img = torch.zeros(
            (batch_size, num_pillar, self._out_channels),
            dtype=neighbors.dtype,
            device=neighbors.device
        )
        # Assign features to nonempty pillars.
        img[mask] = self._fn(
            torch.cat((self._mlp(neighbors), self._zeros))[indices]
        )
        # Reshape into a N-D image.
        return img.permute(0, 2, 1).reshape(
            batch_size, self._out_channels, self._h, self._w
        ).contiguous()
